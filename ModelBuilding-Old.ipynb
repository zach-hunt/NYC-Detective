{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f16a091d-644e-4dd7-b0b9-6eaed1e22bcb",
   "metadata": {},
   "source": [
    "# Image Processing Project - NYC Detective\n",
    "Carlos Ponce (`cmp279`)  \n",
    "Zachary Hunt (`zh362`)  \n",
    "Mykyta Turpitka (`mt689`)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e66edea-d9e2-4b6b-9570-e33d804ad432",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef2de6ba-22a8-403e-9c42-ec65683545b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import keras\n",
    "import pickle\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from skimage import io\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D, Dense, Flatten, Dropout\n",
    "from tensorflow.keras.optimizers import SGD, RMSprop\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from keras.preprocessing.image import img_to_array, load_img"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdd35208-f45e-436d-b5b3-e0e73026dd41",
   "metadata": {},
   "source": [
    "## A - Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e751ee8e-5302-40b2-9357-99d72d6acece",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_directory = \"./data/\"\n",
    "photo_directory = input_directory + \"processed/\"\n",
    "with open(input_directory + \"PhotoTable.p\", 'rb') as pickle_file:\n",
    "    photo_info = pickle.load(pickle_file)\n",
    "photo_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d920b266-0d5b-4328-9bd3-72f56ec5b592",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_data(list_of_images):\n",
    "    x = [] # images as arrays\n",
    "    for image in list_of_images:\n",
    "        x.append(img_to_array(load_img(image,target_size=sample_photo.shape)))\n",
    "    return np.array(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f2b2274-58b3-4dea-bdfa-975f66888b39",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = photo_directory\n",
    "training = [train+i for i in os.listdir(train)]\n",
    "sample_photo = io.imread(training[0])\n",
    "image_shape = (124, 187, 1)\n",
    "train_X_raw = prepare_data(training)\n",
    "train_Y_raw = photo_info[\"Target\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30e7a057-78c4-4299-8f2f-a562127ba5c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# (train_X_raw, train_Y_raw), (test_X_raw, test_Y_raw) = mnist.load_data()\n",
    "print(\"Train shapes:\", train_X_raw.shape, \"->\", train_Y_raw.shape)\n",
    "# print(\"Test shapes:\", test_X_raw.shape, \"->\", test_Y_raw.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c5d52c8-e86b-4686-bd7a-67937be30784",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(train_X_raw[0, :, :, 0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e17e1aa6-c9d0-45a5-8731-cb8ce6b2bee9",
   "metadata": {},
   "source": [
    "## B - Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56537704-4055-476e-a4bb-3b00e06c47f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# I chose not to use a function\n",
    "# Reshape to single channel, scale down to [0, 1]\n",
    "train_X = train_X_raw[:, :, :, :1] / 255.0\n",
    "# train_Y = to_categorical(train_Y_raw)\n",
    "train_Y = train_Y_raw"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60a9df40-1dd2-4a44-9f75-33394d4912f8",
   "metadata": {},
   "source": [
    "## C - CNN Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3d4ae75-a7f8-4d53-8f6f-365026f15263",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_cnn(dropout=False, conv_layer2=False, learning_rate=0.001):\n",
    "    # Define using Sequential\n",
    "    model = Sequential()\n",
    "    # Convolution Layer\n",
    "    model.add(\n",
    "        Conv2D(\n",
    "            32,\n",
    "            (3, 3),\n",
    "            activation=\"relu\",\n",
    "            kernel_initializer=\"he_uniform\",\n",
    "            input_shape=image_shape,\n",
    "        )\n",
    "    )\n",
    "    # Maxpooling Layer\n",
    "    model.add(MaxPooling2D((2, 2)))\n",
    "    \n",
    "    if conv_layer2:\n",
    "        # Convolution Layer\n",
    "        model.add(\n",
    "            Conv2D(\n",
    "                64,\n",
    "                (3, 3),\n",
    "                activation=\"relu\",\n",
    "                kernel_initializer=\"he_uniform\",\n",
    "                input_shape=image_shape,\n",
    "            )\n",
    "        )\n",
    "        # Maxpooling Layer\n",
    "        model.add(MaxPooling2D((2, 2)))\n",
    "    \n",
    "    # Flatten Output\n",
    "    model.add(Flatten())\n",
    "    # Droupout Layer\n",
    "    if dropout:\n",
    "        model.add(Dropout(0.5))\n",
    "    # Dense Layer of 100 neurons\n",
    "    model.add(Dense(100, activation=\"relu\", kernel_initializer=\"he_uniform\"))\n",
    "    model.add(Dense(1, activation=\"softmax\"))\n",
    "    # Initialize Optimizer\n",
    "    opt = RMSprop(lr=learning_rate)  # , momentum=0.9)\n",
    "    # Compile Model\n",
    "    model.compile(optimizer=opt, loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22b08c7d-0962-4848-be0c-8195176018a4",
   "metadata": {},
   "source": [
    "## D - Training and Evaluating CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "377d9076-9412-4ab1-a1ee-7b567f537499",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_Y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c8edf90-3660-437b-9724-7ab074b8c47e",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99f9d068-8a8c-4427-b5d9-21256136ddb9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model = create_cnn(conv_layer2=True)  # dropout=True, learning_rate=1e-06)\n",
    "model.fit(train_X, train_Y, batch_size=32, epochs=10, validation_split=0.1)\n",
    "# score = model.evaluate(test_X, test_Y, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e3fa148-88dd-4ac7-989c-5747ae368deb",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f315c78-1192-4dbe-a46f-e069d91a7417",
   "metadata": {},
   "source": [
    "## E - Experimentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0c606e1-91fd-49b2-ad9b-3070b6e5762f",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X[:5].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2aa6ea82-3758-4051-8cf8-7aa46c5a88d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.predict(train_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89c0293c-0797-43a6-93d0-7996868e519c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:datasci] *",
   "language": "python",
   "name": "conda-env-datasci-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
